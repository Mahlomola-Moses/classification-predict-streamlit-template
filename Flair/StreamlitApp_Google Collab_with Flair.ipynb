{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "flair_nlp_3_0_streamlit.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hF-RNKVpRELr"
      },
      "source": [
        "# Launching Team JS2's Streamlit App from Google Collab using NGROK as our Host"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uC4n_z2WVKs8"
      },
      "source": [
        "### Upload this notebook to googe collab to continue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xylc8DxCRF3V"
      },
      "source": [
        "### Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-output": false,
        "id": "K265ptcpt1Xn"
      },
      "source": [
        "!pip install flair \n",
        "!pip install allennlp==0.9.0\n",
        "!pip install streamlit\n",
        "!pip install pyngrok"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdUeYcVUPKmG"
      },
      "source": [
        "### Link your Google Drive\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbuPNoqWVNF5"
      },
      "source": [
        "First add our Streamlit Repository to your google drive with this link: https://drive.google.com/drive/folders/1z2IXEgANQFHiTuC92BaJj49_6pzJfPEJ?usp=sharing\n",
        "\n",
        "It will be added to your Shared With Me section. To add it to My Drive where it can be acessed by Google Collab:\n",
        "Right click the folder \"classification-predict-streamlit-template\" and select ADD SHORTCUT TO DRIVE\n",
        "\n",
        "Then continue running the cells below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5rtXAxhgy1u",
        "outputId": "6242b6db-38a7-4d20-9951-aca039961ea1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBzeJNTknU12",
        "outputId": "814c5749-b154-4455-aa1c-f7dec3846b98"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet') "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcRwp4ACPRnU"
      },
      "source": [
        "### The Streamlit App"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yRKkekaFPgx",
        "outputId": "20583c82-2f4a-4786-97c3-c94c5ba62267"
      },
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import joblib,os\n",
        "\n",
        "# Data dependencies\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set(font_scale=1.4)\n",
        "\n",
        "import flair\n",
        "import allennlp\n",
        "from flair.data import Sentence\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from wordcloud import WordCloud\n",
        "from PIL import Image\n",
        "\n",
        "# Vectorizer\n",
        "news_vectorizer = open(\"/content/drive/MyDrive/classification-predict-streamlit-template/resources/tfidfvect.pkl\",\"rb\")\n",
        "tweet_cv = joblib.load(news_vectorizer) # loading your vectorizer from the pkl file\n",
        "# Model\n",
        "@st.cache(allow_output_mutation=True, show_spinner=False) \n",
        "def load_data(df):\n",
        "\tdataframe = pd.read_csv('/content/drive/MyDrive/classification-predict-streamlit-template/'+ df + '.csv', index_col = 0)\n",
        "\treturn dataframe\n",
        "@st.cache(allow_output_mutation=True, show_spinner=False)\n",
        "def load_model(model):\n",
        "\tpredictor = joblib.load(open(os.path.join(\"/content/drive/MyDrive/classification-predict-streamlit-template/resources/\" + model + \".pkl\"),\"rb\"))\n",
        "\treturn predictor\n",
        "\n",
        "def switch_demo(x):\n",
        "\tswitcher = {\n",
        "\t\t\t0:\"Neutral:\",\n",
        "\t\t\t1: \"Pro: Believes in man-made climate change\",\n",
        "\t\t\t2: \"News\",\n",
        "\t\t\t-1: \"Anti: Doesn't believe in man-made climate change\" }\n",
        "\treturn switcher.get(x[0], x)\n",
        "\n",
        "@st.cache(allow_output_mutation=True, show_spinner=False)\n",
        "def clean_tweets(message, remove_stopwords=False, eda = False, lemma=True):\n",
        "    \"\"\"\n",
        "    A function to preprocess tweets for model training and exploratory data analysis\n",
        "    :param message: String, message to be cleaned\n",
        "    :param remove_stopwords: Bool, defualt is False, set to true to remove stopwords\n",
        "    :param eda: Bool, defualt is False, set to true to return cleaned but readable string\n",
        "    :param lemma: Bool, deafautl is True, lemmatize.\n",
        "    return: String, message\n",
        "    \"\"\"    \n",
        "    if eda == False:\n",
        "        # change all words into lower case\n",
        "        message = message.lower()\n",
        "    \n",
        "    if eda == True:\n",
        "        message = re.sub('RT|rt','retweet',message)\n",
        "\n",
        "    # replace all url-links with url-web\n",
        "    url = r'http[s]?://(?:[A-Za-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9A-Fa-f][0-9A-Fa-f]))+'\n",
        "    message = re.sub(url, 'web', message)\n",
        "    # removing all punctuation and digits\n",
        "    message = re.sub(r'[-]',' ',message)\n",
        "    message = re.sub(r'[_]', ' ', message)\n",
        "    message = re.sub(r'[^\\w\\s]','',message)\n",
        "    message = re.sub('[0-9]+', '', message) \n",
        "    message = re.sub(r'[!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~âã¢¬¦¢’‘‚…]', ' ', message)\n",
        "    message = re.sub(\"â|ã|Ã|Â\", \" \", message)  # removes strange character \n",
        "    message = re.sub(\"\\\\s+\", \" \", message)  # fills white spaces\n",
        "    message = message.lstrip()  # removes whitespaces before string\n",
        "    message = message.rstrip()  # removes whitespaces after string \n",
        "    \n",
        "    if remove_stopwords == True:     \n",
        "        # remove stopwords if wordcloud\n",
        "        stop_words = stopwords.words('english')\n",
        "        stop_words.append('web')\n",
        "        stop_words.append('climate')\n",
        "        stop_words.append('change')\n",
        "        stop_words.append('global')\n",
        "        stop_words.append('warming')\n",
        "        stop_words.append('retweet')\n",
        "        stop_words.append('u')\n",
        "        message = ' '.join([word for word in message.split(' ') if not word in stop_words])\n",
        "    \n",
        "    if lemma == True:    \n",
        "      # lemmatizing all words\n",
        "        lemmatizer = WordNetLemmatizer()\n",
        "        message = [lemmatizer.lemmatize(token) for token in message.split(\" \")]\n",
        "        message = [lemmatizer.lemmatize(token, \"v\") for token in message]\n",
        "        message = \" \".join(message)\n",
        "\n",
        "    return message\n",
        "\n",
        "def hashtag_extract(x):\n",
        "    \"\"\"\n",
        "    Function to extract the hashtags from the messages column\n",
        "    \"\"\"\n",
        "    hashtags = []    \n",
        "    for i in x:\n",
        "        ht = re.findall(r\"#(\\w+)\", i)\n",
        "        hashtags.append(ht)\n",
        "    return hashtags\n",
        "\n",
        "def graph_model_performances(df, column):\n",
        "\t\t\"\"\"\n",
        "\t\tA function to graph model performances from a dataframe. \n",
        "\t\t:param df: Dataframe\n",
        "\t\t:param column: String, column to sort by\n",
        "\t\treturn: Graph\n",
        "\t\t\"\"\"  \n",
        "\t\tif column == ' ': \n",
        "\t\t\treturn \n",
        "\t\telse:\t\n",
        "\t\t\tdf = df.sort_values(column, ascending=True)\n",
        "\t\t\t\n",
        "\t\t\tif column == 'F1-Weighted':\n",
        "\t\t\t\txlim = [0.6, 0.81]\n",
        "\t\t\tif column == 'F1-Accuracy':\n",
        "\t\t\t\txlim = [0.6, 0.81]\n",
        "\t\t\tif column == 'F1-Macro':\n",
        "\t\t\t\txlim = [0.5, 0.8]  \n",
        "\t\t\tif column == 'Execution Time':\n",
        "\t\t\t\tdf = df.sort_values(column, ascending=False)\n",
        "\t\t\t\txlim = [0.6, 295]  \n",
        "\t\t\tif column == 'CV_Mean':\n",
        "\t\t\t\txlim = [0.6, 0.76]\t\t\t\n",
        "\t\t\tif column == 'CV_Std':\n",
        "\t\t\t\txlim = [0.002, 0.009]\n",
        "\t\t\tif 'Flair_TextClassifier' in df.index: \n",
        "\t\t\t\tfigsize = (14, 5.8) \t\t\t\n",
        "\t\t\t\ttitle = column\n",
        "\t\n",
        "\t\t\telse:\n",
        "\t\t\t\tfigsize = (10, 5.8) \n",
        "\t\t\t\ttitle = False \n",
        "\n",
        "\t\t\tfig, ax = plt.subplots(figsize=figsize, dpi = 550)\n",
        "\n",
        "\t\t\tdf.plot(y=column, kind='barh', xlim=xlim, color= '#18330C', edgecolor = '#8C1010', \n",
        "\t\t\t\t\t\t\tfontsize=16, title= title, ax = ax, width =0.3)\n",
        "\t\t\n",
        "\t\t\n",
        "\t\treturn  st.pyplot(fig), st.dataframe(df.sort_values(column, ascending= False))\n",
        "\n",
        "def graph_model_improvement(tuned_models_performance, models_performance, column):\n",
        "    \"\"\"\n",
        "    A function to visualise model improvements after hyperparameter tuning \n",
        "    :param tuned_models_performance: Dataframe of model performances after tuning\n",
        "    :param models_performance:       Dataframe of model performances beofre tuning\n",
        "    :column:                         String, column to sort by\n",
        "    return: Graph\n",
        "    \"\"\"  \n",
        "    after = tuned_models_performance.sort_values(column,ascending=True)\n",
        "    before = models_performance.sort_values(column,ascending=True)\n",
        "    \n",
        "    if column == 'Execution Time':\n",
        "        xlim = [0.9, 220]\n",
        "        after = tuned_models_performance.sort_values(column,ascending=False)\n",
        "        before = models_performance.sort_values(column,ascending=False)\n",
        "    else:\n",
        "        xlim = [0.6, 0.8]\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(10, 5.8), dpi = 550)\n",
        "    ax.set_xlim(xlim)\n",
        "    plt.rcParams['font.size'] = '12'\n",
        "\n",
        "    models_after_tuning = after[column].index\n",
        "    metrics_after = after[column]\n",
        "    metrics_before = before[column][models_after_tuning]\n",
        "\n",
        "    after_tuning = ax.barh(y= models_after_tuning, width= metrics_after, height =0.3, color= 'blue', \n",
        "                                   edgecolor = 'red',label = 'AFTER TUNING')\n",
        "    before_tuning = ax.barh(y=models_after_tuning, width= metrics_before, height =0.3, color= '#18330C', \n",
        "                        edgecolor = 'red', label = 'BEFORE TUNING')\n",
        "    ax.set_title(column)\n",
        "\n",
        "    return st.pyplot(fig), st.dataframe(tuned_models_performance.sort_values(column, ascending= False))\n",
        "\n",
        "def plot_message_len(messages):\n",
        "\tfig, ax = plt.subplots(dpi = 600, figsize=(15,10))\n",
        "\n",
        "\t#Positive \n",
        "\tsns.distplot(messages, hist=True, kde=True,\n",
        "\t\t\t\tbins=10, color = 'blue', \n",
        "\t\t\t\tax = ax)\n",
        "\t\n",
        "\tax.set_xlabel('Message Length')\n",
        "\tax.set_ylabel('Density')\n",
        "\treturn st.pyplot(fig)\n",
        "\n",
        "def plot_hashtags(df, n):\n",
        "\t# selecting top 10 most frequent hashtags     \n",
        "\tdf = df.nlargest(columns=\"Count\", n = n) \n",
        "\tfig, ax = plt.subplots(figsize = (12.5, 10), dpi = 500)\n",
        "\tax = sns.barplot(data=df, x= \"Count\", y = \"Hashtag\", palette='winter')\n",
        "\tax.set(xlabel = 'Count')\n",
        "\treturn st.pyplot(fig)\n",
        "\n",
        "def create_wordcloud(tweets, n):\n",
        "\tfig, ax = plt.subplots(figsize=(22, 15), dpi = 500)\n",
        "\twc = WordCloud(width=800, height=500, \n",
        "               background_color='black',\n",
        "               max_words = n,\n",
        "               max_font_size=130, random_state=42)\n",
        "\twc.generate(tweets)\n",
        "\tplt.imshow(wc, interpolation='bilinear')\n",
        "\tplt.axis(\"off\")\n",
        "\n",
        "\treturn st.pyplot(fig)\n",
        "\n",
        "# Load your raw data\n",
        "train = pd.read_csv(\"/content/drive/MyDrive/classification-predict-streamlit-template/train.csv\")\n",
        "@st.cache(allow_output_mutation=True, show_spinner=False)\n",
        "def load_bulk_data():\n",
        "\n",
        "\tpro_len = train[train['sentiment']==1]['message'].str.len()\n",
        "\tnews_len = train[train['sentiment']==2]['message'].str.len()\n",
        "\tanti_len = train[train['sentiment']==-1]['message'].str.len()\n",
        "\tneutral_len = train[train['sentiment']==0]['message'].str.len()\n",
        "\n",
        "\t# extracting hashtags from train tweets\n",
        "\tanti_hashtag = hashtag_extract(train['message'][train['sentiment'] == -1])\n",
        "\tneutral_hashtag = hashtag_extract(train['message'][train['sentiment'] == 0])\n",
        "\tpro_hashtag = hashtag_extract(train['message'][train['sentiment'] == 1])\n",
        "\tnews_hashtag = hashtag_extract(train['message'][train['sentiment'] == 2])\n",
        "\n",
        "\tanti_hash = nltk.FreqDist(sum(anti_hashtag,[]))\n",
        "\tanti_hash_df = pd.DataFrame({'Hashtag': list(anti_hash.keys()),\n",
        "\t\t\t\t\t'Count': list(anti_hash.values())})\n",
        "\tpro_hash = nltk.FreqDist(sum(pro_hashtag,[]))\n",
        "\tpro_hash_df = pd.DataFrame({'Hashtag': list(pro_hash.keys()),\n",
        "\t\t\t\t\t'Count': list(pro_hash.values())})\n",
        "\tneutral_hash = nltk.FreqDist(sum(neutral_hashtag,[]))\n",
        "\tneutral_hash_df = pd.DataFrame({'Hashtag': list(neutral_hash.keys()),\n",
        "\t\t\t\t\t'Count': list(neutral_hash.values())})\n",
        "\tnews_hash = nltk.FreqDist(sum(news_hashtag,[]))\n",
        "\tnews_hash_df = pd.DataFrame({'Hashtag': list(news_hash.keys()),\n",
        "\t\t\t\t\t'Count': list(news_hash.values())})\n",
        "\n",
        "\ttrain['message_clean_eda']=train['message'].apply(lambda x: clean_tweets(message =x, remove_stopwords=True, \n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\teda=True, lemma=False))\n",
        "\n",
        "\tnews_tweets = ' '.join([text for text in train['message_clean_eda']\n",
        "\t\t\t\t\t\t\t[train['sentiment'] == 2]])\n",
        "\tpro_tweets = ' '.join([text for text in train['message_clean_eda']\n",
        "\t\t\t\t\t\t[train['sentiment'] == 1]])\n",
        "\tneutral_tweets = ' '.join([text for text in train['message_clean_eda']\n",
        "\t\t\t\t\t\t\t[train['sentiment'] == 0]])\n",
        "\tanti_tweets = ' '.join([text for text in train['message_clean_eda']\n",
        "\t\t\t\t\t\t\t[train['sentiment'] == -1]])\n",
        "\ttweet_list = [news_tweets, pro_tweets,neutral_tweets, anti_tweets]\n",
        "\n",
        "\treturn pro_len, news_len, anti_len, neutral_len, anti_hash_df, pro_hash_df, neutral_hash_df, news_hash_df, tweet_list\n",
        "\n",
        "pro_len, news_len, anti_len, neutral_len, anti_hash_df, pro_hash_df, neutral_hash_df, news_hash_df, tweet_list = load_bulk_data()\n",
        "\n",
        "def plot_mentions(n):\n",
        "\t\t\t\n",
        "\t\t\t# Extracting Users(@) tags in a column\n",
        "\t\t\ttrain['users'] = [''.join(re.findall(r'@([a-zA-Z0-9_]{1}[a-zA-Z0-9_]{0,14})', line)) \n",
        "                       if '@' in line else np.nan for line in train.message]\n",
        "\t\t\tfig, axs = plt.subplots(figsize = (20, 35), dpi=600)\n",
        "\n",
        "\t\t\tsns.countplot(y=\"users\", hue=\"sentiment\", data = train, palette='bright',\n",
        "              order=train.users.value_counts().iloc[:n].index, ax=axs)\n",
        "\t\t\tplt.yticks(fontsize= 25)\n",
        "\t\t\tplt.xticks(fontsize= 20)\n",
        "\t\t\tplt.ylabel('User tags')\n",
        "\t\t\tplt.xlabel('Number of Tags')\n",
        "\t\t\tplt.legend(prop={'size': 30})\n",
        "\t\t\treturn st.pyplot(fig)\n",
        "\n",
        "# The main function where we will build the actual app\n",
        "def main():\n",
        "\t\"\"\"Tweet Classifier App with Streamlit \"\"\"\n",
        "\n",
        "\t# Creates a main title and subheader on your page -\n",
        "\t# these are static across all pages\n",
        "\t# Creating sidebar with selection box -\n",
        "\t# you can create multiple pages this way\n",
        "\toptions = [\"Home\", \"About The Project\", \"Make A Prediction\", \"Assess Our Models\", \"Gain Insight\"]\n",
        "\tselection = st.sidebar.selectbox(\"Options\", options)\n",
        "\n",
        "\t# Building the Home Page\n",
        "\tif selection == \"Home\":\n",
        "\t\tbanner = Image.open('/content/drive/MyDrive/classification-predict-streamlit-template/climate-change-definition-meaning.jpg')\n",
        "\t\tst.image(banner,use_column_width=True)\n",
        "\t\tst.header(\"**Climate Change Tweet Classification**\")\n",
        "\t\tst.title(\"\")\n",
        "\t\tst.subheader(\"***by Team JS2***\")\n",
        "\t\tst.header(\"\\n\\n\")\n",
        "\t\tst.header(\"/ Showcasing the machine learning models we've built to classify tweets \\\n",
        "\t\t\tabout climate change after analysing the sentiment of the tweets.  /\")\n",
        "\t\tst.header(\"\\n\\n\")\n",
        "\t\tst.header(\"\\n\\n\")\n",
        "\t\tst.header(\"\\n\\n\")\n",
        "\t\tst.header(\"\\n\\n\")\n",
        "\t\tst.write('Navigating the sidebar options:')\n",
        "\t\tst.write('**About The Project:** Problem statement, building the solution and introducing the data.')\n",
        "\t\tst.write('**Make A Prediction:** Enter text and predict the sentiment using one of our trained classification models')\n",
        "\t\tst.write(\"**Assess Our Models:**  See how well the different models performed and compare to each other \\\n",
        "\t\t\tusing different evaluation methods and metrics\")\n",
        "\t\tst.write('**Gain Insight:** Exlore the data through interactive visuals')\n",
        "\t\t\n",
        "\n",
        "\n",
        "\t# Building out the \"Information\" page\n",
        "\tif selection == \"About The Project\":\n",
        "\t\tbanner = Image.open('/content/drive/MyDrive/classification-predict-streamlit-template/climate-change-definition-meaning crop.jpg')\n",
        "\t\tst.image(banner,use_column_width=True)\n",
        "\t\tst.header(\"Climate Change Tweet Classification\")\n",
        "\t\tst.title(\"About The Project\")\t\n",
        "\t\tst.header('\\n')\n",
        "\t\t# You can read a markdown file from supporting resources folder\n",
        "\t\tst.subheader(\"**Problem Statement:**\\n \\\n",
        "\t\t\tConstruct a classification algorithm, capable of \\\n",
        "\t\t\taccurately predicting whether or not a person believes in climate change.\")\n",
        "\t\tst.subheader(\"**Building The Solution:**\\n \\\n",
        "\t\t\tWe trained a few Supervised Machine Learning Classification Models to take in a message from \\\n",
        "\t\t\ttwitter and predict its sentiment. Each models accuracy was calculated by comparing the predicted\\\n",
        "\t\t\tsentiment to the actual sentiment.\")\n",
        "\t\tst.subheader(\"**The Data:**\\n \\\n",
        "\t\t\tThe actual sentiment of 15819 tweets along with the message was made available to us for use in training our models.\\n \\n\\\n",
        "\t\t\tThe collection of this data was funded by a Canada Foundation for Innovation JELF Grant to Chris Bauch, University of Waterloo. \\\n",
        "\t\t\tThe dataset aggregates tweets pertaining to climate change collected between Apr 27, 2015 and Feb 21, 2018\")\n",
        "\t\tst.subheader(\"**The Sentiment:**\\n \\\n",
        "\t\t\t2 - News: the tweet links to factual news about climate change \\n\\n 1 - Pro: the tweet supports the belief \\\n",
        "\t\t\tof man-made climate change \\n\\n 0 - Neutral: the tweet neither supports nor refutes the belief of man-made\\\n",
        "\t\t\tclimate change \\n\\n -1 - Anti: the tweet does not believe in man-made climate change Variable definitions\")\n",
        "\n",
        "\t\tst.subheader(\"**Raw Twitter Data and Sentiment**\")\n",
        "\n",
        "\t\tif st.checkbox('Show raw data'): \n",
        "\t\t\tn_rows = st.slider('Number of rows to display', 10, 50, 15, 5)\n",
        "\t\t\tn = st.slider('Starting row number', 0, 15810)\n",
        "\t\t\tst.table(train[['sentiment', 'message']].iloc[n:n_rows + n].style.hide_index()) # will display df\n",
        "\n",
        "\t# Building out the predication page\n",
        "\tif selection == \"Make A Prediction\":\n",
        "\t\tbanner = Image.open('/content/drive/MyDrive/classification-predict-streamlit-template/climate-change-definition-meaning crop.jpg')\n",
        "\t\tst.image(banner,use_column_width=True)\n",
        "\t\tst.header(\"Climate Change Tweet Classification\")\n",
        "\t\tst.title(\"Tweet Classifer\")\n",
        "\t\tst.header('\\n')\n",
        "\t\toptions = ['Linear Support Vector Classifier', 'Logistic Regression', 'Stochastic Gradient Descent Classifier', 'Ridge Classifier', 'Flair Text Classifier']\t\n",
        "\t\tst.info(\"Select a classification model and enter some text to predict the sentiment.\")\n",
        "\t\tmodel = st.selectbox('Select A Model', options)\n",
        "\t\tflair_classifier = load_model('flair_classifier') \n",
        "\n",
        "\t\t# Creating a text box for user input\n",
        "\t\ttweet_text = st.text_area(\"Enter Text\",\"Type Here\")\n",
        "\t\tcleaned_tweet_text = clean_tweets(tweet_text)\n",
        "\t\tclassify = st.button(\"Classify\")\n",
        "\n",
        "\t\tif model == options[0]:   # Prediction with LinearSVC \n",
        "\t\t\tif classify:\n",
        "        # Transforming user input with vectorizer \n",
        "\t\t\t  vect_text = tweet_cv.transform([cleaned_tweet_text]).toarray()\n",
        "        # Load your .pkl file with the model of your choice + make predictions\n",
        "        # Try loading in multiple models to give the user a choice \n",
        "\t\t\t  predictor = joblib.load(open(os.path.join(\"/content/drive/MyDrive/classification-predict-streamlit-template/resources/LinearSVC.pkl\"),\"rb\")) \n",
        "\t\t\t  prediction = predictor.predict(vect_text)\n",
        "\n",
        "        # When model has successfully run, will print prediction\n",
        "        # You can use a dictionary or similar structure to make this output\n",
        "        # more human interpretable. \n",
        "\t\t\t  st.success(\"Predicted sentiment as: \"+ switch_demo(prediction)) \n",
        "\t\t\tst.header('\\n') \n",
        "\t\t\tst.header('\\n') \n",
        "\t\t\tst.header('\\n') \n",
        "\t\t\tif st.checkbox('Show Model info'):\n",
        "\t\t\t\tst.write(\"The objective of the Linear SVC is to fit to the data provided, returning a best fit hyperplane that divides, or categorizes, data.\\\n",
        "\t\t\t\t\tAfter getting the hyperplane,the features are fed to the classifier to see what the predicted class is.\")\n",
        "\n",
        "\t\telif model == options[1]:   # Logistic Regression \n",
        "\t\t\tif classify:\n",
        "\t\t\t  vect_text = tweet_cv.transform([cleaned_tweet_text]).toarray() \n",
        "\t\t\t  predictor = load_model('LogReg') \n",
        "\t\t\t  prediction = predictor.predict(vect_text) \n",
        "\t\t\t  st.success(\"Predicted sentiment as: \"+ switch_demo(prediction)) \n",
        "\t\t\tst.header('\\n') \n",
        "\t\t\tst.header('\\n') \n",
        "\t\t\tst.header('\\n') \n",
        "\t\t\tif st.checkbox('Show Model info'):\n",
        "\t\t\t\tst.write(\"Logistic Regression is basically a supervised classification algorithm. In a \\\n",
        "\t\t\t\t\tclassification problem, the target variable(or output), y, can take only discrete values for given set\\\n",
        "\t\t\t\t\t\tof features(or inputs), X. Just like Linear Regression, it assumes that \\\n",
        "\t\t\t\t\tthe data follows a linear function, Logistic Regression models the data using the sigmoid function.\")\n",
        "\t\t\n",
        "\t\telif model == options[2]:   # SGDClassifier \n",
        "\t\t\tif classify:\n",
        "\t\t\t  vect_text = tweet_cv.transform([cleaned_tweet_text]).toarray() \n",
        "\t\t\t  predictor = load_model('SGDClassifier') \n",
        "\t\t\t  prediction = predictor.predict(vect_text) \n",
        "\t\t\t  st.success(\"Predicted sentiment as: \"+ switch_demo(prediction)) \n",
        "\t\t\tst.header('\\n') \n",
        "\t\t\tst.header('\\n') \n",
        "\t\t\tst.header('\\n') \n",
        "\t\t\tif st.checkbox('Show Model info'):\n",
        "\t\t\t\tst.write(\"SGD is a simple, efficient approach to fitting linear classifiers and regressors under convex loss \\\n",
        "\t\t\t\t\tfunctions such as (linear) Support Vector Machines and Logistic Regression. It has received a considerable \\\n",
        "\t\t\t\t\t\tamount of attention just recently in the context of large-scale learning.\")\n",
        "\t\t\n",
        "\t\telif model == options[3]:   # Ridge \n",
        "\t\t\tif classify:\n",
        "\t\t\t\tvect_text = tweet_cv.transform([cleaned_tweet_text]).toarray() \n",
        "\t\t\t\tpredictor = load_model('RidgeClassifier') \n",
        "\t\t\t\tprediction = predictor.predict(vect_text) \n",
        "\t\t\t\tst.success(\"Predicted sentiment as: \"+ switch_demo(prediction)) \n",
        "\t\t\tst.header('\\n') \n",
        "\t\t\tst.header('\\n') \n",
        "\t\t\tst.header('\\n') \n",
        "\t\t\tif st.checkbox('Show Model info'):\n",
        "\t\t\t\tst.write(\"The Ridge Classifier, based on Ridge regression method, converts the label data into -1, 1 and solves the\\\n",
        "\t\t\t\t\tproblem with regression method. The highest value in prediction is accepted as a target class and for \\\n",
        "\t\t\t\t\t\tmulticlass data muilti-output regression is applied.\")\n",
        "\t\t\n",
        "\t\telif model == options[4]:  # Flair Text Classifier\n",
        "\t\t\tif classify: \n",
        "\t\t\t\tsentence= Sentence(tweet_text) \n",
        "\t\t\t\tflair_classifier.predict(sentence) \n",
        "\t\t\t\tst.success(\"Predicted sentiment as: \"+ str(sentence.labels[0]).split(' ')[0])\n",
        "\t\t\tst.header('\\n') \n",
        "\t\t\tst.header('\\n') \n",
        "\t\t\tst.header('\\n')\n",
        "\t\t\tif st.checkbox('Show Model info'): \n",
        "\t\t\t\tst.write(\"The model takes word embeddings, puts them into an recurrent neural network to obtain a text \\\n",
        "        representation, and puts the text representation in the end into a linear layer to get the actual class label.\")\n",
        "   \n",
        "\t\t\t\n",
        "\n",
        "\tif selection == \"Assess Our Models\":\n",
        "\t\tbanner = Image.open('/content/drive/MyDrive/classification-predict-streamlit-template/climate-change-definition-meaning crop.jpg')\n",
        "\t\tst.image(banner,use_column_width=True)\n",
        "\t\tst.header(\"Climate Change Tweet Classification\")\n",
        "\t\tst.title(\"Model Assessment\")\n",
        "\t\tst.header(\"\\n\\n\")\n",
        "\t\tst.info(\"Graph the performance of our trained machine learning models below\")\n",
        "\n",
        "\t\tclf_performance_df = load_data('clf_performance_df')\n",
        "\t\tordered_CV_clf_performance_df = load_data('ordered_CV_clf_performance_df')\n",
        "\t\tbest_performing_df = load_data('best_performing_df')\n",
        "\t\tCV_best_performing_df = load_data('CV_best_performing_df')\n",
        "\t\tmetrics_new_data_split_df = load_data('metrics_new_data_split_df')\n",
        "\n",
        "\t\toptions = [\"All Models\", \"Top 4\", \"Hyperparameter Tuned Top 4\", \"The Best\"]\n",
        "\t\toption = st.selectbox('1. Select models to evaluate:', options)\t\n",
        "\t\tmethods = [' ', 'Train Test Split', 'Cross Validation']\n",
        "\t\tmethod = st.selectbox('2. Select the training method:', methods)\n",
        "\t\tmetrics = [' ', 'F1-Accuracy', 'F1-Macro', 'F1-Weighted', 'Execution Time', 'CV_Mean', 'CV_Std']\t\n",
        "\n",
        "\t\tif option == options[0]:\n",
        "\t\t\tif method == methods[1]:\n",
        "\t\t\t\tcolumn = st.selectbox('3. Select an evaluation metric:',\n",
        "\t\t\t\t\t\t     metrics[:5])\n",
        "\t\t\t\tif options[0]:\t\t\t\t \n",
        "\t\t\t\t\t\ta = 1+1\n",
        "\t\t\t\t\n",
        "\t\t\t\tgraph_model_performances(clf_performance_df, column)\n",
        "\t\t\t\n",
        "\t\t\telif method == methods[2]:\n",
        "\t\t\t\tcolumn = st.selectbox('3. Select an evaluation metric:',\n",
        "\t\t\t\t\t\t     metrics[4:])\n",
        "\t\t\t\tif options[0]:\t\t\t\t \n",
        "\t\t\t\t\t\ta = 1+1\n",
        "\t\t\t\t\n",
        "\t\t\t\tgraph_model_performances(ordered_CV_clf_performance_df, column)\n",
        "\n",
        "\t\t\n",
        "\t\telif option == options[1]:\n",
        "\t\t\tif method == methods[1]:\t\n",
        "\t\t\t\tcolumn = st.selectbox('3. Select an evaluation metric:',\n",
        "\t\t\t\t\t\t     metrics[:5])\n",
        "\t\t\t\tif options[0]:\t\t\t\t \n",
        "\t\t\t\t\t\ta = 1+1\n",
        "\t\t\t\tgraph_model_performances(clf_performance_df.sort_values('F1-Accuracy')[-4:], column)\n",
        "\t\t\t\n",
        "\t\t\telif method == methods[2]:\n",
        "\t\t\t\tmetrics000 = [' ', 'F1-Accuracy', 'F1-Macro', 'F1-Weighted', 'Execution Time', 'CV_Mean', 'CV_Std']\t\n",
        "\t\t\t\tcolumn = st.selectbox('3. Select an evaluation metric:',\n",
        "\t\t\t\t\t\t     metrics[4:])\n",
        "\t\t\t\tif options[0]:\t\t\t\t \n",
        "\t\t\t\t\t\ta = 1+1\n",
        "\t\t\t\t\n",
        "\t\t\t\tgraph_model_performances(ordered_CV_clf_performance_df[:-5], column)\n",
        "\t\t\n",
        "\t\telif option == options[2]: \n",
        "\t\t\tif method == methods[1]:\t\n",
        "\t\t\t\tcolumn = st.selectbox('3. Select an evaluation metric:',\n",
        "\t\t\t\t\t\t     metrics[:5])\n",
        "\t\t\t\tif column == metrics[0]:\n",
        "\t\t\t\t\ta = 1+1\n",
        "\t\t\t\t\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t    graph_model_improvement(best_performing_df, clf_performance_df, column)\n",
        "\t\t\t\n",
        "\t\t\telif method == methods[2]:\n",
        "\t\t\t\tmetrics000 = [' ', 'F1-Accuracy', 'F1-Macro', 'F1-Weighted', 'Execution Time', 'CV_Mean', 'CV_Std']\t\n",
        "\t\t\t\tcolumn = st.selectbox('3. Select an evaluation metric:',\n",
        "\t\t\t\t\t\t     metrics[4:])\n",
        "\t\t\t\tif options[0]:\t\t\t\t \n",
        "\t\t\t\t\t\ta = 1+1\n",
        "\t\t\t\t\n",
        "\t\t\t\tgraph_model_improvement(CV_best_performing_df, ordered_CV_clf_performance_df, column)\n",
        "\n",
        "\t\telif option == options[3]: \n",
        "\t\t\tif method == methods[1]:\t\n",
        "\t\t\t\tcolumn = st.selectbox('3. Select an evaluation metric:',\n",
        "\t\t\t\t\t\t     metrics[:5])\n",
        "\t\t\t\tif column == metrics[0]:\n",
        "\t\t\t\t\ta = 1+1\n",
        "\t\t\t\t\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t    graph_model_performances(metrics_new_data_split_df, column)\n",
        "\t\t\t\n",
        "\t\t\telif method == methods[2]:\n",
        "\t\t\t\tst.write('Comapring the models to the flair text classifier neural network by means of cross validation \\\n",
        "\t\t\t\tis too computationally expensive and therefore only a train test split was carried out.')\n",
        "\t\t\t\t\n",
        "\n",
        "\tif selection == \"Gain Insight\":\n",
        "\t\tbanner = Image.open('/content/drive/MyDrive/classification-predict-streamlit-template/climate-change-definition-meaning crop.jpg')\n",
        "\t\tst.image(banner,use_column_width=True)\n",
        "\t\tst.header(\"Climate Change Tweet Classification\")\n",
        "\t\tst.title(\"Gain Insight\")\n",
        "\t\tst.subheader('Explore the labled data.')\n",
        "\t\tst.subheader('\\n ')\n",
        "\t\tst.sidebar.markdown('Select sentiment:')\n",
        "\t\tANTI = st.sidebar.checkbox('Anti')\n",
        "\t\tNEUTRAL = st.sidebar.checkbox('Neutral')\n",
        "\t\tPRO = st.sidebar.checkbox('Pro')\n",
        "\t\tNEWS = st.sidebar.checkbox('News')\n",
        "\t\tst.sidebar.markdown('Select info:')\n",
        "\t\twordcloud = st.sidebar.checkbox('Wordclouds')\n",
        "\t\thashtags = st.sidebar.checkbox('Hashtags')\n",
        "\t\tmentions = st.sidebar.checkbox('Mentions')\n",
        "\t\tmessage_len = st.sidebar.checkbox('Message length')\n",
        "\n",
        "\t\tif ANTI:\n",
        "\t\t\tst.write('\\+ tweets labled Anti')\n",
        "\t\tif NEUTRAL:\n",
        "\t\t\tst.write('\\+ tweets labled Neutral')\n",
        "\t\tif PRO:\n",
        "\t\t\tst.write('\\+ tweets labled Pro')\n",
        "\t\tif NEWS:\n",
        "\t\t\tst.write('\\+ tweets labled News')\n",
        "\t\tif wordcloud: \n",
        "\t\t\tst.title('Wordcloud')\n",
        "\t\t\tn = st.slider('Max Words',15, 60, 30, 15)\n",
        "\t\t\tif ANTI:\n",
        "\t\t\t\tst.subheader('Most Popular Words For Anti Tweets')\n",
        "\t\t\t\tcreate_wordcloud(tweet_list[3], n)\n",
        "\t\t\tif NEUTRAL:\n",
        "\t\t\t\tst.subheader('Most Popular Words For Neutral Tweets')\n",
        "\t\t\t\tcreate_wordcloud(tweet_list[2], n)\n",
        "\t\t\tif PRO:\n",
        "\t\t\t\tst.subheader('Most Popular Words For Pro Tweets')\n",
        "\t\t\t\tcreate_wordcloud(tweet_list[1], n)\n",
        "\t\t\tif NEWS:\n",
        "\t\t\t\tst.subheader('Most Popular Words For News Tweets')\n",
        "\t\t\t\tcreate_wordcloud(tweet_list[0], n)\n",
        "\t\tif hashtags:\n",
        "\t\t\tst.title('Popular Hashtags')\n",
        "\t\t\th = st.slider('Max Hashtags',8, 32, 12, 4)\n",
        "\t\t\tif ANTI:\n",
        "\t\t\t\tst.subheader('Most Popular Hashtags for Anti Tweets')\n",
        "\t\t\t\tplot_hashtags(anti_hash_df, h)\n",
        "\t\t\tif NEUTRAL:\n",
        "\t\t\t\tst.subheader('Most Popular Hashtags For Neutral Tweets')\n",
        "\t\t\t\tplot_hashtags(neutral_hash_df, h)\n",
        "\t\t\tif PRO:\n",
        "\t\t\t\tst.subheader('Most Popular Hashtags For Pro Tweets')\n",
        "\t\t\t\tplot_hashtags(pro_hash_df, h)\n",
        "\t\t\tif NEWS:\n",
        "\t\t\t\tst.subheader('Most Popular Hashtags For News Tweets')\n",
        "\t\t\t\tplot_hashtags(news_hash_df, h)\n",
        "\t\tif message_len:\n",
        "\t\t\tst.title('Tweet Lengths')\n",
        "\t\t\tif ANTI:\n",
        "\t\t\t\tst.subheader('Tweet length Distribution - Anti')\n",
        "\t\t\t\tplot_message_len(anti_len)\n",
        "\t\t\tif NEUTRAL:\n",
        "\t\t\t\tst.subheader('Tweet length Distribution - Neautral')\n",
        "\t\t\t\tplot_message_len(neutral_len)\n",
        "\t\t\tif PRO:\n",
        "\t\t\t\tst.subheader('Tweet length Distribution - Pro')\n",
        "\t\t\t\tplot_message_len(pro_len)\n",
        "\t\t\tif NEWS:\n",
        "\t\t\t\tst.subheader('Tweet length Distribution - News')\n",
        "\t\t\t\tplot_message_len(news_len)\n",
        "\t\tif mentions:\n",
        "\t\t\tst.subheader('Popular Mentions')\n",
        "\t\t\tn = st.slider('Max Mentions',5, 35, 15, 5)\n",
        "\t\t\tst.header('Top ' + str(n) + ' Most Popular Tags')\n",
        "\t\t\tplot_mentions(n)\n",
        "\t\telse:\n",
        "\t\t\tst.header('\\n\\n')\n",
        "\t\t\tst.header('\\n\\n')\n",
        "\t\t\tst.header('\\n\\n')\n",
        "\t\t\tst.info(\"From the sidebar select the sentiments you would like to compare and \\\n",
        "\t\t\t\tselect what type of information should be displayed.\")\n",
        "\n",
        "# Required to let Streamlit instantiate our web app.  \n",
        "if __name__ == '__main__':\n",
        "\tmain()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IZ5A3WqPccd"
      },
      "source": [
        "### Create an NGROK account and substitute XXXX your authentication token below:\n",
        "You'll see the token immedietly after signing up."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpdFCJH-FzAB",
        "outputId": "4c5d6523-2c6b-4e76-f9fd-dff0dbbfe94f"
      },
      "source": [
        "#!ngrok authtoken 1ADADAOQb3Q1fbKQTQR4asj_4pADRNUEatKKFSAHyi6jk8\n",
        "!ngrok authtoken XXXX"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRiz_NecGS8M"
      },
      "source": [
        "from pyngrok import ngrok"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHDJ-iexPpMA"
      },
      "source": [
        "### Run Streamlit App"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-WnFERvGTBL"
      },
      "source": [
        "!streamlit run --server.port 80 app.py &>/dev/null&"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eP1ieBTZGTF6"
      },
      "source": [
        "publ_url = ngrok.connect(port='8502')    # Could be port number 8500/ 8501/8502"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5albtp0QXjq"
      },
      "source": [
        "### Go to the app at the link created below: i.e. something like http://878754557cab.ngrok.io/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pv7gVH3pGTJQ",
        "outputId": "df97a99a-9a55-447f-ec3e-4822439ece7f"
      },
      "source": [
        "publ_url    "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<NgrokTunnel: \"http://878754557cab.ngrok.io\" -> \"http://localhost:80\">"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28m7qBVvQwFK"
      },
      "source": [
        "#### Run this cell every 30 min to keep Google Collab from Disconnecting while the Streamlit App is Live"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lD_eNXCicMU1",
        "outputId": "292506bb-382d-4b10-9011-2a02f59f04ee"
      },
      "source": [
        "1+1      # Run this cell every 30 min to keep Google Collab from Disconnecting while the Streamlit App is Live"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2krVl3OqGTDo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c374b69c-a58e-41a0-e388-ab00504b9007"
      },
      "source": [
        "!pgrep streamlit  # The google collable process for streamlit"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "988\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MdpaMiL1ZYC"
      },
      "source": [
        "!kill 988  # enter the process number to terminate streamlit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-YW-WRQTcNk"
      },
      "source": [
        "ngrok.kill()  # Shutdown your NGROK Server"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuI8RCO3t1X4"
      },
      "source": [
        "#### References\n",
        "- https://medium.com/@jcharistech/how-to-run-streamlit-apps-from-colab-29b969a1bdfc\n",
        "\n"
      ]
    }
  ]
}